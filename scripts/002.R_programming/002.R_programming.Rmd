---
title: "Coursera: R Programming"
author: "Jessica Grindheim"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_width: 7
    fig_height: 6
    fig_caption: true
    toc: yes
    toc_float: true
    toc_depth: 6
    df_print: paged
  pdf_document: 
    toc: yes
    toc_depth: 6
latex_engine: xelatex
geometry: left = 1in, right = 1in, top = 1in, bottom = 1in
---

```{r setup , include=FALSE}
knitr::opts_chunk$set(
    echo = F
  , message = F
  , warning = F
  , fig.fullwidth = T
  , fig.align = "center"
  , fig.margin = T
  , tidy.opts = list(width.cutoff=80)
  ) 

# the following colors the boxes in knit html
# https://www.r-bloggers.com/2017/06/pretty-errors-warnings-and-messages-in-r-markdown/
knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
)
```


# Background

* **Goals**  
  * Take notes during the course  
  * Do necessary exercises  
  



```{r, include = F}
library("here")
source(here::here("scripts","002.R_programming","002.config.R"))

```

# Module 1

* **Data Types- R objects and attributes**  
  * **attributes**  
    * names, dimnames  
    * dimensions  
    * class    
    * length  
    * other user-defined attributes  
* **Data Types- Matrices**  
  * matrices are just a vector with a dimension attribute  
  * creating them is a pain in the butt becuase they are created column-wise (fill up first column with vector, then go to second column, ....)  
* **Data Types- Missing values**   
  * **NA**  
  * **NaN**  
    * not a number  
  * NaN is also NA, but not the reverse  
* **Data Types- Data Frames**  
  * matrices have to have the same type of value (becuase they are a vector), but data frames can have different types of values.  
    * coerce a data frame with many different types to a matrix?  The values will be coerced to the least common denominator (maybe character)  

* **reading data**   
  * dump (the opposite of source!)  
  * load is for reading files that were written into binary  
  * read.table will auto-skip any lines that being with a "#* symbol!  read.csv is the same, but assume comma-delimiting  and header is always = T  
  * reading large datastes with read.table  
    *  nrows argument is nice- juust read in a few rows so you can look without reading the whole thing in!  
* **dumping and dputting**  
  * dputting R objects  
    * writes R code that can be used to constructs R code to recreate an object!  awesome for stack overflow!  Can also save the code as .R   
  * dump is like dput, but you can do it on a bunch of objects  
  
* **Data Types- **  
* **Data Types- **  
* **Data Types- **  

## quiz 

```{r}
# read in data
DAT = read.csv( here::here(
  "rawdata"
  , "002.R_programming"
  , "module.1"
  , "hw1_data.csv"
))
```

# Module 2

* **Control structures in R: if-else**  
  * while (a loop that will stop)  
    * be careful, can accidentally create a endless loop  
  * break  
  * repeat  
    * initiates an infinite loop  
    * only way to stop is to call break()  
    * helpful if stats optimization  
    * probably better to use a for loop with a hard stop because this might work forever  

* **formal arguments**  
  * "..." argument  
     * a variable number of arguments passed onto other functions
* **scoping**  
  * 

## programming assignment 

### pollutantmean

* Write a function named 'pollutantmean' that calculates the mean of a pollutant (sulfate or nitrate) across a specified list of monitors. The function 'pollutantmean' takes three arguments: 'directory', 'pollutant', and 'id'. Given a vector monitor ID numbers, 'pollutantmean' reads that monitors' particulate matter data from the directory specified in the 'directory' argument and returns the mean of the pollutant across all of the monitors, ignoring any missing values coded as NA. A prototype of the function is as follows  

```{r}


pollutantmean = function(directory = here::here( "rawdata", "002.R_programming" , "module.2" , "specdata"), pollutant = c("sulfate","nitrate"), id = 1:332){
  
  # all files
  files = list.files(directory, full.names = T)
  # subset of files with specified IDs
  # only works becuase of the naming of the files matches the order of the files.  Dumb.
  files = sapply( id , function(i){
    files[i]
  })
  
  # read in files and make a table
  tRes = lapply( files, function(f){
    D = read.csv( f )
  return(D) })
  DAT = dplyr::bind_rows(tRes)
  
  # return mean of the pollutant
  res = mean( DAT[,pollutant[1]], na.rm = T )
  return(res) }

# make sure the results match the example
pollutantmean(
  "pollutant" = "sulfate"
  , "id" =  1:10
)

pollutantmean(
  "pollutant" = "nitrate"
  , "id" =  70:72
)
pollutantmean(
  "pollutant" = "nitrate"
  , "id" =  23
)

pollutantmean(
  "pollutant" = "sulfate"
  , "id" =  34
)

pollutantmean(
  "pollutant" = "nitrate"
  
)
```

### complete
* Write a function that reads a directory full of files and reports the number of completely observed cases in each data file. The function should return a data frame where the first column is the name of the file and the second column is the number of complete cases. A prototype of this function follows  

```{r}

complete = function( directory = here::here( "rawdata", "002.R_programming" , "module.2" , "specdata"), id = 1:332 ){
   # all files
  files = list.files(directory, full.names = T)
  # loop through files. read in, count complete cases
  # return a dataframe of results
  tRes = data.frame(t( sapply( id, function(i){
    # init
    toReturn = list()
    # read in data
    D = read.csv( files[i] )
    # count complete cases
    count = nrow( D[complete.cases(D), ] )
    
    # finalize
    toReturn[[ "id" ]] = i
    toReturn[[ "nobs" ]] = count
    
  return(toReturn) }) ))
  # format tRes
  rownames(tRes) = NULL
  for (c in colnames(tRes)){ tRes[,c] = unlist(tRes[,c]) }
  
return(tRes) }

# make sure the results match the example



complete(
  "id" = c(2, 4, 8, 10, 12)
  )
complete(
  "id" =30:25
  )
complete(
  "id" = 3
  )

# quiz
cc = complete(
  "id" = c(6, 10, 20, 34, 100, 200, 310)
  )
print(cc$nobs)


cc = complete(
  "id" = c(54)
  )
print(cc$nobs)

# quiz 7
RNGversion("3.5.1")  
set.seed(42)
cc <- complete(
  "id" = 332:1
  )
use <- sample(332, 10)
print(cc[use, "nobs"])


```

### corr

* Write a function that takes a directory of data files and a threshold for complete cases and calculates the correlation between sulfate and nitrate for monitor locations where the number of completely observed cases (on all variables) is greater than the threshold. The function should return a vector of correlations for the monitors that meet the threshold requirement. If no monitors meet the threshold requirement, then the function should return a numeric vector of length 0. A prototype of this function follows  


```{r}

corr = function( directory = here::here( "rawdata", "002.R_programming" , "module.2" , "specdata"), threshold = 0){
  
  # all files
  files = list.files(directory, full.names = T)
  
  # get a table counting complete cases
  D.complete = complete()
  
  # filter to min number complete cases
  D.complete = D.complete[D.complete[,"nobs"] > threshold, ]
  
  # loop through files with min complete cases
  correlation = c()
  for (id in D.complete$id){
       # file of interest
    f = files[id]
    # read in data
    DAT = read.csv(f)
    DAT = DAT[complete.cases(DAT[,c("nitrate","sulfate")]),] # subset to complete cases of variables
    # correlate
    res = cor( 
      "x" = DAT$nitrate
      , "y" = DAT$sulfate
     
      )
    correlation = c(correlation, res)
  }

  # return vector of correlations
  return(correlation)
  
  
}



# make sure the results match the example



cr <- corr( 
  "threshold" = 150
  )
head(cr)
summary(cr)


cr <- corr( 
  "threshold" = 400
  )
head(cr)
summary(cr)


cr <- corr( 
  "threshold" = 5000
  )
summary(cr)
length(cr)


# quiz 8
cr <- corr()                
cr <- sort(cr)   
RNGversion("3.5.1")
set.seed(868)                
out <- round(cr[sample(length(cr), 5)], 4)
print(out)

# quiz 9
cr <- corr(
   "threshold" = 129
   ) 
cr <- sort(cr)                
n <- length(cr)    
RNGversion("3.5.1")
set.seed(197)                
out <- c(n, round(cr[sample(n, 5)], 4))
print(out)

# quiz 10

cr <- corr(
   "threshold" = 2000
   )                
n <- length(cr)                
cr <- corr(
   "threshold" = 1000
   )                
cr <- sort(cr)
print(c(n, round(cr, 4)))
```



# Module 3

## apply
* works on the margins of an array  
  
```{r}

apply(
  "X" = matrix( rnorm(200), 20 , 10) # 20 rows, 10 columns
  , "MARGIN" = 1  # 1 for rows, 2 for columns
  , "FUN" = mean 
    )

# functions that do it very fast, faster than apply
args(rowSums)
args(rowMeans)
args(colSums)
args(colMeans)

```

## mapply
* multivariate version of other apply  
  * suppose you have two lists and the elements of list1 are used for arg1 and the elements of list2 are used for arg2  

  
```{r}
# different setup than lapply or sapply because giving it an unknown number of lists
mapply(
  "FUN" =  # number of args has to be at least as many as the number of lists
  , ... # where you pass lists to mapply
  , "MoreArgs" = NULL
  )

list( rep(1,4)
      , rep(2,3)
      , rep(3,2)
      , rep(4,1) 
      )

mapply( rep # repeats x (first arg) and a number of times
        , 1:4 # first list/vector
        , 4:1 # second list/vector
        )
```
## tapply
* applied over subsets of a vector  
  
```{r}

# generate the mean of subgroups
X = c( rnorm(10), runif(10), rnorm(10,1) ) # vector of length 30
f = gl(3,10) # generates 3 factor levels each of length of 10

tapply(
  "X" = X # a vector
  , "INDEX" = f  # a vector of the same length of X which indentifies groups. Probably should be a factor?
  , "FUN" = mean # function you want to do to some subsets of X

  )

tapply(
  "X" = X # a vector
  , "INDEX" = f  # a vector of the same length of X which indentifies groups. Probably should be a factor?
  , "FUN" = range # function you want to do to some subsets of X

  )
```


## split
* takes a vector of other objects and splits it into groups determined by a factor or list of factors  
* use in conjuction with sapply or lapply  
* nice because can split complicated objects

```{r}

X = c( rnorm(10), runif(10), rnorm(10,1) ) # vector of length 30
f = gl(3,10) # generates 3 factor levels each of length of 10



split( # returns a list that can be putinto lapply or sapply
  "x" = X  # vector/list/dataframe
  , "f" = f # factor or list of factors
  )


# tapply could do this too, just an example
lapply(
  split( # returns a list that can be putinto lapply or sapply
    "x" = X  # vector/list/dataframe
    , "f" = f # factor or list of factors
  )
  , mean
)

# splitting a dataframe
library(datasets)
head(airquality)
# want to calculate mean of temp, wind, etc by month
# so split by month, then calculate the means

s = split(
  "x" = airquality
  , "f" = airquality$Month
)
sapply( s, function(x){
  colMeans( x[,c("Ozone", "Solar.R", "Wind")] , na.rm = T)
})

# splitting on more than 1 level
x = rnorm(10)
f1 = gl(2,5) # factor 1
f2 = gl(5,2) # factor 2
 
interaction(f1,f2) # combo factor 1+2

split(
  "x" = x
  , "f" = list(f1,f2) # can call interaction(f1,f2) for you!
  , "drop" = T # drops empty levels created by splitting (some emptly levels can be created if no instances)
)


```

## debugging tools
* they come in R, not part of a package  
* can be useful in figuring out what's wrong when you know there's a problem  
* **How do you know there's a problem?**  
  * message: could be nothing  
  * warning: next level up, doesn't have to stop the function.  Something unexpected happened.    
  * error:  fatal problem, execution stops (from stop() function)      
  * condition:  a generic concept that something unexpected can occur.  Programmers can create their own conditions    
  * invisible: a function that prevents auto-printing!
  

* **traceback**  
  * 
* **debug**  
  * flags that function for debug mode.  Anytime that function is called, it will halt execution of the function at the first line in a browser and can run through the function expression by expression  
* **browser**  
  * like debug, can stick the browser call anywhere in the code and whenever it is called, can go line-by-line from there  
* **trace**  
  * allows you to insert debugging code into a function without editing the function- useful when you're debugging somebody else's code like in a package  
* **recover**  
  * related to traceback  
  * when you get an error, usually you get a message and go back to the console  
  * can change the default behavior by setting an error handler-- anytime you get an error, instead of giving back the console, will freeze it...and I didn't follow  
  
```{r}

# traceback
rm(x)
mean(x)
traceback() # tells you where the error occurs, in this case, right at the top of the mean function

# 
rm(x)
rm(y)
lm(y~x)   # x and y don't exists
traceback()
```

```{r}
# debug

debug(lm)
lm( y~x )
# first prints out whole function body
# then have browser below, which is just like a workspace
# hit "n" then enter and it runs the next line
# keep hitting n-ENTER until you find the issue

```

```{r}

# recover

# set the global option in this R session
# then when there's an error, it doesn't go to the console, it gives you choices
options(error = recover)

read.csv("nosuchfile")

```

```{r}

```

```{r}

```

  
  



# Module 4



# Session info

```{r}

sessionInfo()
knitr::knit_exit()
```


